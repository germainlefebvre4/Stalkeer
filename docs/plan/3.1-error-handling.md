# Task 3.1: Error Handling & Resilience

**Phase**: 3 (Polish, Integration & Deploy)  
**Complexity**: Medium  
**Status**: Completed

## Description

Implement comprehensive error handling throughout the application with proper logging, retries, and graceful degradation.

## Details

- Create error package at `/internal/errors/` or extend existing:
  - Define custom error types:
    - `ValidationError` - input validation failures
    - `DatabaseError` - database operation failures
    - `ParseError` - M3U parsing failures
    - `ClassificationError` - content classification failures
    - `ExternalServiceError` - Radarr/Sonarr API failures
    - `ConfigError` - configuration issues
  
  - Implement error wrapping with context
  - Error codes and categorization

- Implement retry logic:
  - Exponential backoff for transient failures
  - Max retry attempts configuration
  - Jitter to prevent thundering herd
  - Specific retry triggers (connection timeout, 429, 5xx errors)

- Implement graceful shutdown:
  - Handle SIGINT, SIGTERM signals
  - Close database connections cleanly
  - Stop in-progress processing
  - Flush pending operations

- Implement structured logging:
  - JSON format for machine parsing
  - Request ID tracking for correlation
  - Log levels: DEBUG, INFO, WARN, ERROR
  - Context injection (user, endpoint, operation)
  - Stacktraces for errors

- Error recovery in M3U parsing:
  - Skip corrupt entries and log details
  - Continue processing after errors
  - Track error statistics per file

- Connection pooling and circuit breaker:
  - Implement circuit breaker pattern for external APIs
  - Monitor connection pool health
  - Fallback strategies

- Unit tests:
  - Test error creation and wrapping
  - Test retry logic with different scenarios
  - Test graceful shutdown handling
  - Test structured logging output

## Dependencies

- All Phase 2 tasks (to retrofit error handling)

## Acceptance Criteria

- [x] Custom error types defined for all failure scenarios
- [x] Retry logic functional with exponential backoff
- [x] Graceful shutdown cleans up resources
- [x] Structured logging in JSON format with context
- [x] M3U parser recovers from corrupt entries
- [x] Error messages helpful for diagnosis
- [x] Unit tests cover error paths
- [x] No unhandled panics in production code

## Completion Notes

- Custom error types implemented in `/internal/errors/errors.go` with comprehensive error codes
- Error wrapping with context using `AppError` struct
- Retry logic with exponential backoff in `/internal/retry/retry.go`
  - Configurable max attempts, backoff multiplier, and jitter
  - Context-aware cancellation support
  - Generic `DoWithResult` for functions returning values
- Graceful shutdown handler in `/internal/shutdown/shutdown.go`
  - SIGINT and SIGTERM signal handling
  - Configurable shutdown timeout
  - LIFO execution order for cleanup functions
  - Concurrent shutdown function execution
- Circuit breaker pattern in `/internal/circuitbreaker/circuitbreaker.go`
  - Three states: Closed, Open, Half-Open
  - Configurable failure threshold and timeout
  - Half-open state for recovery testing
- Integrated graceful shutdown into server command with:
  - HTTP server shutdown with context
  - Database connection cleanup
  - 30-second shutdown timeout
- All packages have comprehensive test coverage (100% pass rate)
- Structured logging with field support throughout application
