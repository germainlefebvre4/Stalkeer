# Task 4.3.1: Complete Resume Downloads Execution

## Overview

**Problem**: The resume downloads feature currently only identifies and lists incomplete downloads but doesn't execute the actual resumption. The `ResumeHelper.ResumeDownloads()` method logs downloads and marks them as skipped, lacking integration with the download execution engine.

**Solution**: Implement the actual download execution logic in `ResumeHelper.ResumeDownloads()` by:
- Integrating with the existing `ParallelDownloader` for concurrent downloads
- Retrieving ProcessedLine data for each incomplete download to get URLs and metadata
- Building proper DownloadOptions from DownloadInfo records
- Supporting partial file resume where possible
- Providing detailed progress reporting and error handling

**Success Criteria**:
- `resume-downloads` command actually downloads files, not just lists them
- Downloads resume from partial files when possible
- Progress is displayed for each download
- Statistics accurately reflect resumed/failed/completed downloads
- Integration with radarr/sonarr `--resume` flag works end-to-end
- Code reuses existing ParallelDownloader and download infrastructure

**Users & Usage**:
- **System Administrators**: Run `stalkeer resume-downloads` to complete interrupted downloads
- **Automated Systems**: Use `stalkeer radarr/sonarr --resume` in scheduled jobs
- **Developers**: Consistent download behavior across all commands

---

## Technical Approach

### Architecture Overview

The solution enhances `ResumeHelper` to orchestrate actual download execution:

1. **Download Information Retrieval**:
   - Query DownloadInfo records for incomplete downloads
   - Load associated ProcessedLine records to get URLs and metadata
   - Extract movie/TV show details for path construction

2. **Download Job Creation**:
   - Convert each DownloadInfo + ProcessedLine into a DownloadJob
   - Reconstruct original download paths from metadata
   - Determine if partial resume is possible

3. **Parallel Execution**:
   - Use existing ParallelDownloader for concurrent downloads
   - Respect configured parallelism limits
   - Handle progress callbacks and error reporting

4. **State Management**:
   - Leverage existing StateManager for lock management
   - Update states through Download() method (already implemented)
   - Track statistics for reporting

### Key Technology Choices

- **Reuse ParallelDownloader**: No need to recreate parallel execution logic
- **Database Joins**: Efficiently load DownloadInfo with ProcessedLine in single query
- **Existing Download()**: Already handles locking, state updates, progress persistence
- **Path Reconstruction**: Use metadata from Movie/TVShow records to rebuild paths

### Major Technical Decisions

**Decision 1: Reuse vs. Duplicate Code**
- **Chosen**: Reuse ParallelDownloader and existing Download() method
- **Rationale**: Avoids code duplication, ensures consistent behavior
- **Trade-off**: Need to reconstruct DownloadOptions from stored data

**Decision 2: Path Reconstruction Strategy**
- **Chosen**: Query Movie/TVShow records to rebuild original paths
- **Rationale**: Ensures consistency with original download locations
- **Alternative**: Store full path in DownloadInfo (future enhancement)

**Decision 3: Partial File Handling**
- **Chosen**: Check for .partial files in temp directory, resume if valid
- **Rationale**: Maximizes bandwidth savings
- **Trade-off**: Additional validation overhead

**Decision 4: Error Handling**
- **Chosen**: Individual download failures don't stop batch
- **Rationale**: Maximize successful completions
- **Trade-off**: Need comprehensive statistics reporting

---

## Implementation Plan

### Phase 1: Data Retrieval Enhancement (Small)

**Objective**: Load all necessary data to reconstruct download jobs

**Tasks**:

1. **Enhance GetIncompleteDownloads** [Medium]
   - Add eager loading of ProcessedLine associations
   - Include Movie/TVShow data via joins
   - Return enriched data structure with all needed information
   - Update StateManager query to use `Preload()` for associations

2. **Create EnrichedDownloadInfo struct** [Small]
   - Struct combining DownloadInfo + ProcessedLine + Movie/TVShow
   - Helper methods to extract URL, title, year, season/episode
   - Path reconstruction logic

3. **Test Data Loading** [Small]
   - Unit test for enriched data loading
   - Verify all associations loaded correctly
   - Test with movies and TV shows

**Dependencies**: None

**Deliverables**:
- Enhanced StateManager query methods
- New `EnrichedDownloadInfo` type
- Unit tests for data loading

---

### Phase 2: Download Job Construction (Medium)

**Objective**: Convert DownloadInfo records into executable DownloadJobs

**Tasks**:

1. **Implement BuildDownloadJob** [Medium]
   - Create DownloadJob from EnrichedDownloadInfo
   - Reconstruct base destination path from metadata
   - Handle movies vs. TV shows path differences
   - Set ProcessedLineID for state tracking

2. **Add Path Reconstruction Logic** [Medium]
   - For movies: `{MoviesPath}/{Title} ({Year})/{Title} ({Year})`
   - For TV shows: `{TVShowsPath}/{Title}/Season {XX}/{Title} - S{XX}E{YY}`
   - Use config paths from Downloads settings
   - Sanitize filenames properly

3. **Implement Partial File Detection** [Small]
   - Check for .partial files in temp directory
   - Validate partial file matches DownloadInfo.BytesDownloaded
   - Return resume capability indicator

4. **Create JobBuilder helper** [Small]
   - Encapsulate job creation logic
   - Handle both resume and fresh download scenarios
   - Apply configuration defaults

**Dependencies**: Phase 1

**Deliverables**:
- `BuildDownloadJob()` function
- Path reconstruction utilities
- Partial file detection logic
- Unit tests for job construction

---

### Phase 3: Parallel Download Execution (Large)

**Objective**: Execute downloads using ParallelDownloader with proper progress tracking

**Tasks**:

1. **Enhance ResumeDownloads Method** [Large]
   - Load enriched download data
   - Build DownloadJobs for each incomplete download
   - Initialize ParallelDownloader with configured concurrency
   - Execute batch download
   - Collect results and update statistics

2. **Implement Progress Tracking** [Medium]
   - Create progress callbacks for each download
   - Track current download index/total
   - Display download name and progress percentage
   - Handle concurrent progress updates (use mutex)

3. **Add Result Processing** [Medium]
   - Process DownloadJobResult from ParallelDownloader
   - Update statistics (resumed, failed, completed)
   - Log detailed results for each download
   - Handle partial successes

4. **Implement Dry-Run Enhancement** [Small]
   - Show what would be downloaded with full details
   - Display path, size, progress information
   - Indicate if resume is possible

**Dependencies**: Phase 2

**Deliverables**:
- Fully functional `ResumeDownloads()` method
- Progress tracking system
- Result processing logic
- Enhanced dry-run output

---

### Phase 4: Integration & Polish (Medium)

**Objective**: Integrate with radarr/sonarr commands and polish UX

**Tasks**:

1. **Create Shared ResumeIncomplete Function** [Medium]
   - Extract common logic for radarr/sonarr integration
   - Function signature: `ResumeIncompleteDownloads(ctx, contentType, opts) (stats, error)`
   - Filter by content type (movies vs. tvshows)
   - Return statistics for reporting

2. **Integrate with Radarr Command** [Small]
   - Call ResumeIncompleteDownloads when `--resume` flag set
   - Filter for movies only
   - Display separate statistics (resumed vs. new downloads)
   - Update command output formatting

3. **Integrate with Sonarr Command** [Small]
   - Call ResumeIncompleteDownloads when `--resume` flag set
   - Filter for TV shows only
   - Apply series-id filter if specified
   - Display separate statistics

4. **Enhanced Output Formatting** [Small]
   - Color-coded status messages (if terminal supports)
   - Progress bars for active downloads
   - Summary table with statistics
   - ETA calculations based on download speed

5. **Error Handling & Edge Cases** [Medium]
   - Handle missing ProcessedLine records (orphaned downloads)
   - Handle missing Movie/TVShow records
   - Handle insufficient disk space
   - Handle network interruptions gracefully
   - Cleanup partial files on non-resumable errors

**Dependencies**: Phase 3

**Deliverables**:
- Shared resume function
- Integrated radarr/sonarr commands
- Enhanced output formatting
- Comprehensive error handling

---

### Phase 5: Testing & Documentation (Medium)

**Objective**: Ensure reliability and document usage

**Tasks**:

1. **Unit Tests** [Medium]
   - Test EnrichedDownloadInfo creation
   - Test job building logic
   - Test path reconstruction
   - Test statistics tracking
   - Mock database queries

2. **Integration Tests** [Large]
   - Test with actual database
   - Test resume from partial files
   - Test concurrent downloads
   - Test failure scenarios
   - Test radarr/sonarr integration

3. **Update Documentation** [Small]
   - Update RESUME-DOWNLOADS.md with execution details
   - Add examples of successful resume operations
   - Document statistics output
   - Add troubleshooting section

4. **Create Usage Examples** [Small]
   - Add to README.md
   - Include common scenarios
   - Show integration with radarr/sonarr

**Dependencies**: Phase 4

**Deliverables**:
- Comprehensive test suite (>80% coverage)
- Updated documentation
- Usage examples
- Troubleshooting guide

---

## Considerations

### Assumptions

- ProcessedLine records exist for all DownloadInfo records
- Movie/TVShow records exist for all ProcessedLines
- Config paths (MoviesPath, TVShowsPath) are accessible and writable
- ParallelDownloader handles all concurrency concerns
- Existing Download() method handles state management correctly
- Database performance adequate for joined queries

### Constraints

- **Code Reuse**: Must use existing ParallelDownloader, not create new parallel execution
- **Backward Compatibility**: ProcessedLine state updates must continue
- **Performance**: Bulk loading should be efficient (avoid N+1 queries)
- **Memory**: Cannot load all downloads into memory for very large backlogs
- **Time**: Should complete in 3-4 days for solo developer

### Risks

**Risk 1: Orphaned DownloadInfo Records**
- **Impact**: Medium - Cannot resume downloads without ProcessedLine
- **Probability**: Low - Should rarely happen with current implementation
- **Mitigation**: Skip orphaned records, log warning, cleanup job to remove them

**Risk 2: Path Reconstruction Errors**
- **Impact**: High - Files downloaded to wrong location
- **Probability**: Medium - Metadata might be missing or incorrect
- **Mitigation**: Validate paths before download, fallback to temp directory, log warnings

**Risk 3: Concurrent Resume Attempts**
- **Impact**: Medium - Duplicate downloads if locking fails
- **Probability**: Low - Locking mechanism in place
- **Mitigation**: Existing lock acquisition in Download() prevents this

**Risk 4: Large Download Backlogs**
- **Impact**: Medium - Memory pressure from loading many records
- **Probability**: Medium - Users with hundreds of failed downloads
- **Mitigation**: Implement pagination/batching in query, process in chunks

**Risk 5: Partial File Corruption**
- **Impact**: Low - Resume fails, restart from beginning
- **Probability**: Low - Validation catches most issues
- **Mitigation**: Delete corrupted partials, restart download

---

## Not Included (Future Enhancements)

These features are valuable but not essential for initial implementation:

1. **Batch Processing for Large Backlogs**: Process downloads in chunks to limit memory
2. **Download Prioritization**: Let users prioritize certain downloads
3. **Bandwidth Management**: Throttle speeds or schedule downloads
4. **Notification System**: Alert on completion or persistent failures
5. **Web UI**: Visual interface for managing downloads
6. **Download Queue Visualization**: See pending downloads in real-time
7. **Advanced Filtering**: Filter by date, size, series, quality
8. **Retry Scheduling**: Exponential backoff for failed downloads over time
9. **Storage Optimization**: Delete or archive old failed downloads automatically
10. **Metrics & Analytics**: Track success rates, bandwidth usage, common failure patterns

---

## Timeline Estimate

**Solo Developer (assuming 20-25 hours/week)**:

- **Phase 1**: 1 day
- **Phase 2**: 1.5 days
- **Phase 3**: 2 days
- **Phase 4**: 1.5 days
- **Phase 5**: 2 days

**Total**: 8 days (1.5-2 weeks)

**Team of 2 Developers**:

- **Phase 1-2**: Parallel - 1.5 days
- **Phase 3**: One developer - 2 days
- **Phase 4**: Can parallelize radarr/sonarr integration - 1 day
- **Phase 5**: Parallel testing/documentation - 1.5 days

**Total**: 6 days (1-1.5 weeks)

---

## Success Metrics

**Quantitative**:
- 100% of identified incomplete downloads attempted
- >90% success rate for resumable downloads
- <5% overhead compared to fresh downloads
- Test coverage >80%
- Zero code duplication with existing download logic

**Qualitative**:
- Users can run one command to complete all interrupted downloads
- Clear progress indication during execution
- Actionable error messages for failures
- Seamless integration with radarr/sonarr workflows
- Consistent behavior across all download scenarios

---

## Code Reuse Strategy

### Existing Components to Leverage

1. **ParallelDownloader** (`internal/downloader/parallel.go`)
   - Already handles concurrent downloads
   - Manages worker pools and job queues
   - Returns results channel

2. **Download() Method** (`internal/downloader/downloader.go`)
   - Already handles locking, state management
   - Progress persistence implemented
   - Error handling and retry logic

3. **StateManager** (`internal/downloader/state_manager.go`)
   - Query methods for incomplete downloads
   - Lock management
   - State transitions

4. **Path Construction** (from `cmd/main.go` radarr/sonarr)
   - Movie path: Lines 519-522
   - TV show path: Lines 721-724
   - Filename sanitization

### New Components Needed

1. **EnrichedDownloadInfo** - Data structure combining all needed info
2. **BuildDownloadJob()** - Convert DownloadInfo to DownloadJob
3. **ResumeIncompleteDownloads()** - Shared function for radarr/sonarr
4. **Progress Tracker** - Concurrent-safe progress display

### Refactoring Opportunities

1. Extract path construction into shared utility functions
2. Create sanitization helper (currently duplicated)
3. Standardize statistics reporting across commands
4. Create shared progress display utilities

---

## Implementation Checklist

- [ ] Phase 1: Data Retrieval Enhancement
  - [ ] Enhance StateManager queries with associations
  - [ ] Create EnrichedDownloadInfo struct
  - [ ] Add unit tests for data loading
  
- [ ] Phase 2: Download Job Construction
  - [ ] Implement BuildDownloadJob()
  - [ ] Add path reconstruction logic
  - [ ] Implement partial file detection
  - [ ] Create JobBuilder helper
  - [ ] Add unit tests for job construction
  
- [ ] Phase 3: Parallel Download Execution
  - [ ] Enhance ResumeDownloads() method
  - [ ] Implement progress tracking
  - [ ] Add result processing
  - [ ] Enhance dry-run output
  - [ ] Add integration tests
  
- [ ] Phase 4: Integration & Polish
  - [ ] Create ResumeIncompleteDownloads()
  - [ ] Integrate with radarr command
  - [ ] Integrate with sonarr command
  - [ ] Enhance output formatting
  - [ ] Comprehensive error handling
  
- [ ] Phase 5: Testing & Documentation
  - [ ] Complete unit test suite
  - [ ] Complete integration tests
  - [ ] Update RESUME-DOWNLOADS.md
  - [ ] Update README.md
  - [ ] Add troubleshooting guide

---

**Created**: February 1, 2026  
**Status**: Ready for Implementation  
**Priority**: High - Completes critical resume downloads feature
