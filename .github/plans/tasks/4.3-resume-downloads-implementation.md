# Resume Downloads Implementation Plan

## Status

**Current State**: ✅ **Infrastructure Complete** - Database schema, state management, and CLI command implemented
**Next Step**: ⏳ **Execution Implementation** - See [Task 4.3.1](4.3.1-resume-downloads-execution.md) for completing download execution

### Completed Components (February 1, 2026)
- ✅ Extended DownloadInfo model with comprehensive state tracking
- ✅ StateManager for state transitions and locking
- ✅ ResumeSupport for HTTP range requests
- ✅ Enhanced Downloader with progress persistence
- ✅ resume-downloads CLI command (identification phase)
- ✅ Integration flags for radarr/sonarr commands
- ✅ Configuration settings and documentation

### Remaining Work
- ⏳ Actual download execution in ResumeHelper (currently logs only)
- ⏳ Integration with ParallelDownloader
- ⏳ Path reconstruction from stored metadata
- ⏳ End-to-end testing with real downloads

See [Task 4.3.1: Resume Downloads Execution](4.3.1-resume-downloads-execution.md) for implementation plan.

---

## Overview

**Problem**: The current download system lacks robust state management for interrupted downloads. When the application stops (gracefully or via crash/shutdown), ongoing downloads are lost. There's no way to identify and resume partially downloaded or failed downloads, leading to wasted bandwidth and incomplete media libraries.

**Solution**: Implement a comprehensive download state management system that:
- Tracks download progress in the database with detailed status information
- Persists download state to survive application restarts
- Provides a `resume-downloads` command to identify and resume interrupted downloads
- Handles partial downloads intelligently (resume vs. restart based on file integrity)

**Success Criteria**:
- All download attempts are tracked in the database with status, timestamps, and error information
- Downloads interrupted by application shutdown can be resumed after restart
- New `resume-downloads` command successfully identifies and processes incomplete downloads
- Download state transitions are properly logged and auditable
- Failed downloads can be retried with exponential backoff
- System handles edge cases (corrupted partial files, stale locks, etc.)

**Users & Usage**:
- **System Administrators**: Use `resume-downloads` after system restarts to recover interrupted downloads
- **Automated Systems**: Scheduled jobs can run `resume-downloads` periodically to ensure all media is downloaded
- **Developers**: Enhanced debugging with detailed download state tracking

---

## Technical Approach

### Architecture Overview

The solution extends the existing download system with:

1. **Enhanced Database Schema**: Extend `DownloadInfo` model with:
   - Detailed status tracking (pending, downloading, paused, completed, failed, retrying)
   - Partial download tracking (bytes downloaded, resume token)
   - Retry attempt counter and last retry timestamp
   - Lock mechanism to prevent concurrent download attempts

2. **Download State Manager**: New component responsible for:
   - State transitions and validation
   - Progress persistence at regular intervals
   - Cleanup of stale locks
   - Download eligibility checks

3. **Resume Downloads Command**: New CLI command that:
   - Queries database for incomplete downloads
   - Validates partial downloads
   - Schedules downloads with parallelization
   - Reports progress and results

4. **Enhanced Downloader**: Modify existing downloader to:
   - Support HTTP range requests for resume capability
   - Persist progress at regular intervals (every N MB or N seconds)
   - Handle partial file validation
   - Update download state throughout lifecycle

### Key Technology Choices

- **Database State Machine**: Use PostgreSQL with GORM for transactional state updates
- **HTTP Range Requests**: Standard HTTP/1.1 range header for resumable downloads
- **File Integrity**: SHA256 checksums for partial file validation (optional)
- **Concurrency Control**: Database row-level locks with timeout for preventing duplicate downloads

### Major Technical Decisions

**Decision 1: Resume Strategy**
- **Chosen**: Support HTTP range requests where available, fallback to full re-download
- **Rationale**: Balances complexity with practical benefit. Many CDNs support range requests
- **Trade-off**: Some downloads may restart from scratch if server doesn't support ranges

**Decision 2: Progress Persistence Interval**
- **Chosen**: Persist every 10MB or 30 seconds (whichever comes first)
- **Rationale**: Balances database write overhead with meaningful resume granularity
- **Trade-off**: May lose up to 10MB of progress on crash

**Decision 3: State Lock Mechanism**
- **Chosen**: Database-based advisory locks with configurable timeout (5 minutes default)
- **Rationale**: Prevents duplicate downloads, survives application restart
- **Trade-off**: Requires cleanup mechanism for stale locks

**Decision 4: Partial File Storage**
- **Chosen**: Store partial files in temp directory with `.partial` extension
- **Rationale**: Clear distinction from complete files, easy cleanup
- **Trade-off**: Requires disk space for partial downloads

---

## Implementation Plan

### Phase 1: Foundation (Database & State Management)

**Objective**: Establish robust state tracking infrastructure

**Tasks**:

1. **Extend DownloadInfo Model** [Medium]
   - Add fields: `bytes_downloaded`, `total_bytes`, `resume_token`, `retry_count`, `last_retry_at`, `locked_at`, `locked_by`
   - Add status enum: `pending`, `downloading`, `paused`, `completed`, `failed`, `retrying`
   - Create database migration
   - Update table name and indexes
   - Add validation methods

2. **Create Download State Manager** [Large]
   - Implement state transition logic with validation
   - Add lock acquisition/release methods
   - Implement stale lock cleanup (locks older than 5 minutes)
   - Add progress update method with rate limiting
   - Create eligibility checker (determines if download should be resumed)
   - Write comprehensive unit tests

3. **Database Migration** [Small]
   - Create migration file for DownloadInfo schema changes
   - Add indexes on `status`, `locked_at`, `updated_at`
   - Create migration rollback logic
   - Update `migrate` command documentation

**Dependencies**: None

**Deliverables**:
- Updated `internal/models/processing_log.go`
- New `internal/downloader/state_manager.go`
- Migration file in `internal/database/migrations/`
- Unit tests with >80% coverage

---

### Phase 2: Enhanced Downloader with Resume Support

**Objective**: Modify downloader to support resumable downloads and state persistence

**Tasks**:

1. **Add Resume Support to Downloader** [Large]
   - Detect server support for HTTP range requests (check `Accept-Ranges` header)
   - Implement partial file validation (check size, optionally checksum)
   - Add logic to resume from partial file if valid
   - Handle range request in `downloadFile` method
   - Add configuration options for resume behavior

2. **Implement Progress Persistence** [Medium]
   - Create progress tracking wrapper
   - Persist state every 10MB or 30 seconds
   - Update `bytes_downloaded` in database
   - Handle persistence errors gracefully (log but don't fail download)

3. **Update Download Lifecycle** [Medium]
   - Acquire lock before download starts
   - Update state to `downloading` with `started_at` timestamp
   - Create partial file with `.partial` extension
   - Persist progress during download
   - Rename partial file on completion
   - Release lock on success/failure
   - Update state to `completed` or `failed` with appropriate metadata

4. **Error Handling & Retry Logic** [Medium]
   - Differentiate retryable vs. non-retryable errors
   - Update `retry_count` and `last_retry_at` on failures
   - Implement exponential backoff (use existing retry package)
   - Set max retry attempts (configurable, default 5)
   - Update error messages in DownloadInfo

5. **Integration Testing** [Medium]
   - Test successful download with state updates
   - Test interrupted download (simulate crash)
   - Test resume from partial file
   - Test fallback when range requests unsupported
   - Test concurrent download prevention via locks
   - Test stale lock cleanup

**Dependencies**: Phase 1

**Deliverables**:
- Updated `internal/downloader/downloader.go`
- New `internal/downloader/resume.go`
- Updated `internal/downloader/parallel.go`
- Integration tests in `internal/downloader/downloader_test.go`

---

### Phase 3: Resume Downloads Command & Integration

**Objective**: Create CLI command to identify and resume incomplete downloads, and integrate resume functionality into existing radarr/sonarr commands

**Tasks**:

1. **Create Command Infrastructure** [Small]
   - Add `resumeDownloadsCmd` to `cmd/main.go`
   - Define command flags: `--dry-run`, `--limit`, `--parallel`, `--max-retries`, `--clean-stale-locks`, `--verbose`, `--service` (filter by radarr/sonarr/all)
   - Add command to root command
   - Write command help text

2. **Implement Resume Logic** [Large]
   - Query database for downloads with status: `pending`, `downloading`, `failed`, `paused`
   - Filter out downloads locked by active processes
   - Clean up stale locks (optional with flag)
   - Exclude downloads exceeding max retry count
   - Sort by priority (failed recently, then oldest first)
   - Apply limit if specified
   - Support filtering by service type (radarr/sonarr) via ProcessedLine content type

3. **Download Orchestration** [Medium]
   - Initialize ParallelDownloader with configured concurrency
   - Build download jobs from incomplete download records
   - Handle dry-run mode (list downloads without executing)
   - Execute downloads with progress tracking
   - Collect and report results (success/failure counts)
   - Update download records based on results

4. **Progress Reporting** [Small]
   - Display summary of found downloads
   - Show real-time progress for each download
   - Print statistics (total, completed, failed, retried)
   - Log detailed information in verbose mode
   - Handle graceful shutdown (SIGINT/SIGTERM)

5. **Integrate Resume into Radarr Command** [Medium]
   - Add `--resume` flag to radarr command
   - When flag is set, check for incomplete movie downloads before fetching new missing items
   - Resume incomplete downloads first (respecting `--limit` and `--parallel` flags)
   - Report separately: resumed vs. newly downloaded items
   - Skip resume if `--dry-run` is enabled (only show what would be resumed)
   - Update radarr command help text with resume flag documentation

6. **Integrate Resume into Sonarr Command** [Medium]
   - Add `--resume` flag to sonarr command
   - When flag is set, check for incomplete TV show downloads before fetching new missing episodes
   - Resume incomplete downloads first (respecting `--limit` and `--parallel` flags)
   - Report separately: resumed vs. newly downloaded items
   - Skip resume if `--dry-run` is enabled (only show what would be resumed)
   - Filter by `--series-id` if specified
   - Update sonarr command help text with resume flag documentation

7. **Create Shared Resume Helper** [Medium]
   - Extract common resume logic into shared helper function/package
   - Function signature: `ResumeIncompleteDownloads(ctx, contentType, opts)`
   - Support filtering by content type (movies, tvshows)
   - Return statistics (resumed count, failed count)
   - Reuse in both resume-downloads command and radarr/sonarr commands
   - Include proper error handling and logging

8. **Documentation** [Small]
   - Update README.md with resume-downloads command
   - Add examples for common use cases
   - Document `--resume` flag for radarr and sonarr commands
   - Document configuration options
   - Add troubleshooting section
   - Update DEVELOPMENT.md with technical details
   - Add workflow examples (e.g., "stalkeer radarr --resume --limit 10")

**Dependencies**: Phase 2

**Deliverables**:
- New file `cmd/resume_downloads.go`
- New file `internal/downloader/resume_helper.go` (shared resume logic)
- Updated `cmd/main.go` (radarr and sonarr commands with `--resume` flag)
- Updated `README.md`
- Updated `docs/DEVELOPMENT.md`
- Unit tests for resume helper functionality

---

### Phase 4: Polish & Deploy

**Objective**: Harden the system, improve observability, and prepare for production

**Tasks**:

1. **Logging & Observability** [Medium]
   - Add structured logging for state transitions
   - Log download resume attempts (with reason)
   - Add metrics for download success/failure rates
   - Track retry statistics
   - Log stale lock cleanups

2. **Configuration** [Small]
   - Add download resume settings to `config.yml`
   - Define defaults: `resume_enabled`, `progress_interval_mb`, `progress_interval_seconds`, `lock_timeout_minutes`, `max_retry_attempts`
   - Update config struct and validation
   - Document configuration options

3. **Edge Case Handling** [Medium]
   - Handle corrupted partial files (delete and restart)
   - Handle disk space issues during resume
   - Handle URL changes (detect via DownloadInfo)
   - Handle very old pending downloads (configurable age limit)
   - Handle orphaned DownloadInfo records (no associated ProcessedLine)

4. **Cleanup Mechanisms** [Small]
   - Extend `cleanup` command to remove old partial files
   - Add flag to clean failed downloads older than N days
   - Add flag to reset stuck downloads
   - Implement cleanup of orphaned DownloadInfo records

5. **Testing & Validation** [Large]
   - Run full test suite
   - Test actual interruption scenarios (kill -9, system shutdown)
   - Validate database migrations (up and down)
   - Test radarr command with `--resume` flag
   - Test sonarr command with `--resume` flag
   - Verify resume works correctly with `--limit` and `--parallel` flags
   - Test filtering by content type (movies vs. tvshows)
   - Verify statistics reporting for resumed vs. new downloas
   - Test resume-downloads in dry-run mode
   - Verify integration with Radarr/Sonarr commands

6. **Documentation Polish** [Small]
   - Add architecture diagram showing state machine
   - Document error codes and troubleshooting
   - Add FAQ section
   - Create example workflows
   - Update STATUS.md

**Dependencies**: Phase 3

**Deliverables**:
- Updated `config.yml` and `config.yml.example`
- Updated `internal/config/config.go`
- Enhanced `cmd/cleanup.go`
- Updated documentation in `docs/`
- All tests passing with >80% coverage
- Production-ready feature

---

## Considerations

### Assumptions

- HTTP servers commonly support range requests (Accept-Ranges header)
- Database is PostgreSQL with GORM ORM
- Download URLs remain valid for reasonable time periods
- Partial files can be safely stored in temp directory
- Most downloads are large enough (>10MB) to benefit from resume

### Constraints

- **Database Performance**: Frequent progress updates could impact database performance
  - *Mitigation*: Rate limit updates to every 10MB or 30 seconds
- **Disk Space**: Partial files consume additional disk space
  - *Mitigation*: Regular cleanup of old partial files
- **Time**: Implementation estimated at 2-3 weeks for solo developer
- **Backward Compatibility**: Must not break existing download functionality
  - *Mitigation*: Feature flag for resume functionality

### Risks

**Risk 1: Database Lock Contention**
- **Impact**: High - Could block downloads
- **Probability**: Medium - Multiple concurrent resume attempts
- **Mitigation**: Use advisory locks with timeout; implement lock queue if needed

**Risk 2: Partial File Corruption**
- **Impact**: Medium - Wasted bandwidth, failed downloads
- **Probability**: Low - File systems are generally reliable
- **Mitigation**: Optional checksum validation; delete corrupted partials

**Risk 3: Server Doesn't Support Range Requests**
- **Impact**: Low - Full re-download required
- **Probability**: Medium - Some CDNs don't support ranges
- **Mitigation**: Fallback to full download; log warning

**Risk 4: Stale Lock Cleanup Conflicts**
- **Impact**: Medium - Could clean up active downloads
- **Probability**: Low - With proper timeout configuration
- **Mitigation**: Conservative timeout (5 minutes); only clean locks with locked_at timestamp

**Risk 5: Database Migration Failures**
- **Impact**: High - Could break existing system
- **Probability**: Low - With proper testing
- **Mitigation**: Thorough migration testing; rollback capability; backup before migration

---

## Not Included (Future Enhancements)

These features are valuable but not essential for initial release:

1. **Distributed Download Coordination**: Support multiple application instances coordinating downloads
   - Would require distributed locking (Redis, etc.)
   - Current solution uses database locks, works for single instance

2. **Bandwidth Throttling**: Limit download speed to prevent network saturation
   - Can be added as configuration option later
   - Low priority for initial release

3. **Download Prioritization**: Allow users to prioritize certain downloads
   - Would require priority field and sorting logic
   - Can be added when user demand exists

4. **Checksum Verification**: SHA256 verification of completed downloads
   - Useful but adds complexity and processing time
   - Not all sources provide checksums

5. **Multi-part Downloads**: Split file into chunks for parallel download
   - Significant complexity increase
   - Most servers limit concurrent connections per IP

6. **Download Scheduling**: Specify time windows for downloads
   - Useful for bandwidth management
   - Can be handled externally with cron

7. **Web UI for Download Management**: Visual interface for monitoring downloads
   - Would require frontend development
   - CLI is sufficient for initial release

8. **Download History & Analytics**: Track historical download performance
   - Nice for insights but not core functionality
   - Logs provide basic tracking

9. **Notification System**: Alert on download completion/failure
   - Could integrate webhooks or email
   - Can be added as separate feature

10. **Alternative Download Sources**: Fallback to alternative URLs on failure
    - Would require source management system
    - Out of scope for current implementation

---

## Timeline Estimate

**Solo Developer (assuming 20-25 hours/week)**:

- **Phase 1**: 4-5 days
- **Phase 2**: 6-8 days  
- **Phase 3**: 6-7 days (extended for radarr/sonarr integration)
- **Phase 4**: 4-6 days

**Total**: 20-26 days (4-5.5 weeks)

**Team of 2 Developers**:

- **Phase 1 & 2**: Parallel development - 6-8 days
- **Phase 3**: Split work (resume-downloads command + radarr/sonarr integration) - 4-5 days
- **Phase 4**: Parallel testing/documentation - 3-4 days

**Total**: 13-17 days (2.5-3.5 weeks)

---

## Success Metrics

**Quantitative**:
- 100% of download state transitions tracked in database
- >95% of interrupted downloads successfully resumed
- <1% of partial file corruptions
- Zero data loss from download state tracking
- <100ms overhead per state update
- Test coverage >80%

**Qualitative**:
- Clear, actionable error messages foradarr/sonarr commands via `--resume` flag
- Clear separation in output between resumed and newly downloaded items
- Consistent behavior across all commands that use resume functionalityad failures
- Intuitive CLI interface for resume-downloads command
- Easy troubleshooting with detailed logging
- Minimal configuration required for default behavior
- Seamless integration with existing commands

---

## Rollout Strategy

1. **Development**: Implement in feature branch
2. **Testing**: Comprehensive testing in development environment
3. **Documentation**: Complete all documentation before merge
4. **Database Migration**: Run migration in staging environment first
5. **Soft Launch**: Enable for internal use, monitor logs
6. **Full Release**: Deploy to production, announce in release notes
7. **Monitoring**: Track download success rates, resume attempts
8. **Iteration**: Gather feedback, address issues in follow-up releases
